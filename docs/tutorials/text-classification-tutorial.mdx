---
title: How MindsDB & Hugging Face Can Help Stop Hate-Speech
sidebarTitle: Use MindsDB's, Hugging Face and MySQL Datasource to Perform NLP Queries that Identify Hate Speech in Your Dataset
---

## Introduction

In today's world, digital conversation is king. Whether it be text message, email, or social media, we do the majority of our communicating in a virtual setting. With all this information spreading around, negative language is bound to start showing up. 

Hate speech is defined as, 'abusive or threatening speech or writing that expresses prejudice on the basis of ethnicity, religion, sexual orientation, or similar grounds'. This offensie language comes in many forms, including memes, messages, social posts, gestures, and icons (even emojis can be used the wrong way these days).

As most of us know, social media provides a speakerphone for hate & negativity. This causes a major problem for us because, unfortunately, misinformation tends to spread faster when people are upset. Thankfully, new technologies & advances in NLP are providing ways to identify (and ween out) the bad, or hateful, content out there before it spreads.

**In this tutorial, you will learn how to use MindsDB and Hugging Face to run text-classification NLP queries on a MySQL database connection and classify hate speech.**

Before you begin, here are some noteworthy concepts:

- [MindsDB](https://mindsdb.com/) is an open-source AI layer for existing databases that allows you to effortlessly develop, train and deploy state-of-the-art machine learning models using SQL queries. 

- [Hugging Face](https://huggingface.co/) is a community and data science platform that provides tools that enable users to build, train and deploy machine learning models based on open source code and technologies. 

- **NLP**, or Natural Language Processing, is a subprocess of artificial intelligence that helps machines process and understand human language so that they can automatically perform repetitive tasks. 
Some examples of NLP include machine translation, summarization, ticket classification, and spell check (or "autocorrect").

## Data Setup

Make sure you have access to a working MindsDB installation, either locally or via [MindsDB Cloud](https://cloud.mindsdb.com/). 

*You can create a **free** MindsDB account and take advantage of their built-in SQL editor [here](https://cloud.mindsdb.com/editor).*

If you want to learn more about creating a free MindsDB Cloud account, follow
[this guide](/setup/cloud/). Another way is to set up
MindsDB locally using
[Docker](/setup/self-hosted/docker/) or
[Python](/setup/self-hosted/pip/source/).

You will need to have MySQL installed locally to follow along with this tutorial. You can learn moree about installing MySQL locally [here]().

carry out the following tasks in your command line:

- Fire up the mysql server

 `mysql.server start`

- Login:

`mysql -u user -p`

- Create your database:

`CREATE DATABASE nlp_mindsdb;`

- Create a table:

```sql
CREATE TABLE tweets (
  id INTEGER,
  hate_speech INTEGER,
  offensive INTEGER,
  neither INTEGER,
  tweet VARCHAR(255),
  PRIMARY KEY (id)
);
```

---

Query OK, 0 rows affected (0.03 sec)

mysql> SHOW TABLES;
+-----------------------+
| Tables_in_nlp_mindsdb |
+-----------------------+
| tweets                |
+-----------------------+
1 row in set (0.00 sec)

---

- Next grant the user access to the new database table:

'GRANT ALL PRIVILEGES ON `nlp_mindsdb.tweets` TO user@localhost;'

***output should read:***
`Query OK, 0 rows affected (0.01 sec)`

---

## Understanding the Data

[Hate-speech-CNERG/bert-base-uncased-hatexplain](https://huggingface.co/Hate-speech-CNERG/bert-base-uncased-hatexplain?text=I+like+you.+I+love+you) is The Hugging Face transformer model you will be using for this exercise. The model is used for classifying a text as Hatespeech, Offensive, or Normal. The model is trained using data from Gab and Twitter and Human Rationales were included as part of the training data to boost the performance. All of the datasets and models for this transformer are available [here](https://github.com/hate-alert/HateXplain).

This next section will show you how to import this [dataset file](https://raw.githubusercontent.com/hate-alert/HateXplain/master/Data/dataset.json), which was converted into a .cvs for this tutorial, into your local MySQL table you created above:

- Load the data from your dataset into the `tweets` table:

```sql
mysql> LOAD DATA LOCAL INFILE '/Users/alissa/Downloads/tweets.csv' INTO TABLE tweets FIELDS TERMINATED BY `,`;
```

```
Query OK, 24784 rows affected, 17300 warnings (0.26 sec)
Records: 26952  Deleted: 0  Skipped: 2168  Warnings: 17300
```

---

- Go ahead and confirm your import:

`SELECT * FROM tweets LIMIT `0`

```sql
------------------------------------------------------------+
    -> | id | hate_speech | offensive | neither | tweet                                                                                                                                         |
    -> +----+-------------+-----------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------+
    -> |  0 |           0 |         0 |       3 | !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your hou |. &amp; as a man you should always take the trash out...
    '> |  1 |           0 |         3 |       0 | !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st plac                                                        |
    '> |  2 |           0 |         3 |       0 | !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she                     |confused as shit
    '> +----+-------------+-----------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------+
```
---

## Connecting To MySQL Datsource

- Now that your MySQL database and table are configured, use *ngrok* to expose your local MySQL server:

`ngrok tcp 3306` 

- Next, head to `https://cloud.mindsdb.com/editor`.

Using SQL's, `CREATE DATABASE` statement and the credentials supplied by `ngrok` output, securely connect to MySQL right inside the MindsDB Cloud Editor:

```sql
CREATE DATABASE twitter_data  --- display name for database.
WITH ENGINE = 'mysql',        --- name of the mindsdb handler
PARAMETERS = {
  "user": "root",             --- your mysql username
  "password": "MyN3wP4ssw0rd",    --- your mysql password  
   "host": "6.tcp.ngrok.io",    ---ngrok host credentials 
  "port": "10105",                  ---ngrok forwarded port
  "database": "nlp_mindsdb"          --- database name
};
```

You should receive the following output,
`Query Successfully Executed`

- Go ahead and confirm the new database includes the tweets table you built in your command line:

```sql
SELECT *
FROM twitter_data.tweets
LIMIT 10;
```

***your output will look like this, but with 10 rows***

| id  | hate_speech | offensive | neither | tweet |
| --- | ----------- | --------- | ------- | ----- |
| 0 | 0 | 0 | 3 | !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out... |
| 1 | 0 | 3 | 0 | !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!! |

---

## Creating a Predictor

Now that you're connected to MySQL, it's time to create your predictor model.

- First, navigate to the mindsdb database:

 `use mindsdb;`

Your output should read:
`Query successfully completed`

- Next, make sure your data is there with SQL's `SELECT` statement in your MindsDB Cloud Editor Instance:

```sql
SELECT *
FROM twitter_data.tweets
LIMIT 3;
```
***your output will look like this, but with 10 rows***

| id  | hate_speech | offensive | neither | tweet |
| --- | ----------- | --------- | ------- | ----- |
| 0 | 0 | 0 | 3 | !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out... |
| 1 | 0 | 3 | 0 | !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!! |

---

- Now, it's time to create your prediction model!

```sql
CREATE MODEL mindsdb.hf_test
PREDICT PRED
USING
engine = 'huggingface',
task = 'text-classification',
model_name = "Hate-speech-CNERG/bert-base-uncased-hatexplain",
input_column = 'tweet',
labels = ['hate_speech', 'neither', 'offensive'];
```

| hf_test | huggingface | mindsdb | true | 1 | generating | [NULL] | PRED | up_to_date | 23.3.4.0 | [NULL] | [NULL] | {'target': 'PRED', 'using': {'task': 'text-classification', 'model_name': 'Hate-speech-CNERG/bert-base-uncased-hatexplain', 'input_column': 'tweet', 'labels': ['hate_speech', 'neither', 'offensive']}}  | [NULL] |


## Checking The Status of a Predictor

- Next up, check the status of your predictor:

```sql
SELECT *
FROM mindsdb.models 
WHERE name = 'hf_test';
```

| hf_test | huggingface | mindsdb | 1 | complete | [NULL] | PRED | up_to_date | 23.3.5.0 | [NULL] | [NULL] | {'target': 'PRED', 'using': {'task': 'text-classification', 'model_name': 'Hate-speech-CNERG/bert-base-uncased-hatexplain', 'input_column': 'tweet', 'labels': ['hate_speech', 'neither', 'offensive']}} | [NULL] | [NULL] | [NULL] | [NULL] | 2023-03-29 17:15:38.683663 |

---

`DESCRIBE PREDICTOR mindsdb.hf_test;`

```sql
{"input_column":"tweet","labels":["hate_speech","neither","offensive"],"labels_map":{"hate speech":"hate_speech","normal":"neither","offensive":"offensive"},"max_length":512,"model_name":"Hate-speech-CNERG/bert-base-uncased-hatexplain","target":"PRED","task":"text-classification","task_proper":"text-classification"}
```

## Training a Predictor

Now that your model is finished generating, you can go ahead and test it out! ***Note: In order to confirm your new model's efficiency, you will most likely use some language you don't like or agree with here. Just keep in mind, you can ultimately use this highly effective technology to do good! Do not follow the tutorial if you intent to use this malicously.***

Test Query Examples:

```sql
SELECT *
FROM mindsdb.hf_test
WHERE text = 'I like you. I love you.';
```

| PRED | PRED_explain | text |
| ---- | ------------ | ---- |
| neither | {"hate_speech":0.03551715984940529,"neither":0.7747423648834229,"offensive":0.18974047899246216} | I like you. I love you. |

---

```sql
SELECT *
FROM mindsdb.hf_test
WHERE text = 'I hate negroes'
```

| PRED | PRED_explain | text |
| ---- | ------------ | ---- |
| hate_speech | {"hate_speech":0.82469242811203,"neither":0.05819767713546753,"offensive":0.11710995435714722} | I hate negroes |

---

```sql
SELECT *
FROM mindsdb.hf_test
WHERE text = 'You are a dumb whore';
```

| PRED | PRED_explain | text |
| ---- | ------------ | ---- |
| offensive | {"hate_speech":0.06079000607132912,"neither":0.35908129811286926,"offensive":0.5801286697387695} | You are a dumb whore |

---

## Conclusion

Great work! By following along with this tutorial, you have successfully done the following things:

- [x] Learned about MindsDB, Hugging Face, and Natural Processing Language
- [x] Learned how to create a database and table locally with MySQL 
- [x] Learned how to use `CREATE DATABASE` in MindsDB to connect to a local MySQL connection
- [x] Learned how to create a prediction model, using the `CREATE PREDICTOR` statement
- [x] Learned how to connect a Hugging Face model to your predictor
- [x] Learned how to train a predictor model in MindsDB

Now that you have this knowledge, you're probably eager to try out new models and NLP tasks. Sign up for a free MindsDB cloud account [here](https://cloud.mindsdb.com/) and get started today!

If you want to learn more about MindsDB, checkout these resources:

- [MindsDB](https://mindsdb.com/)
- [Hugging Face](https://huggingface.co/)

- Engage with the MindsDB community on:
  [Slack](https://mindsdb.com/joincommunity) or
  [GitHub](https://github.com/mindsdb/mindsdb/discussions) to ask questions and
  share your ideas and thoughts.

- If this tutorial was helpful, please give us a GitHub star [here](https://github.com/mindsdb/mindsdb).
