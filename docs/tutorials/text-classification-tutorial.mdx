---
title: How MindsDB & Hugging Face Can Help You Stop The Hate
sidebarTitle: Use MindsDB's, Hugging Face and MySQL Datasource to Peerform NLP Queries that Identify Hate Speech in Your Dataset
---

## Introduction

In today's world, digital conversation is king. Whether it be text message, email, or social media we do the majority of our communicating in a virtual setting. With all this information spreading around, negativity is bound to happen. Luckily, new advances in NLP bring opportunity to identify (and ween out) the bad, or hateful, text content out there using automated processes.

In this tutorial, I'm going to show you how you can use MindsDB and Hugging Face to classify hate speech in your database. Before we begin, let's go over some core concepts:

- [MindsDB](https://mindsdb.com/) is is an open-source AI layer for existing databases that allows you to effortlessly develop, train and deploy state-of-the-art machine learning models using SQL queries. 

- [Hugging Face](https://huggingface.co/) is a community and data science platform that provides tools that enables users to build, train and deploy machine learning models based on open source code and technologies. 

- **NLP**, or Natural Language Processing, is a subprocess of artificial intelligence that helps machines process and understand the human langage so that they can automatically perform repetitive tasks. 
Some examples of NLP include machine translation, summarization, ticket classification, and spell check (or "autocorrect").

## Data Setup

Make sure you have access to a working MindsDB installation, either locally or via [MindsDB Cloud](https://cloud.mindsdb.com/). 

*You can create a **free** MindsDB account and take advantage of their built-in SQL editor [here](https://cloud.mindsdb.com/editor).*

If you want to learn more about creating a free MindsDB Cloud account, follow
[this guide](/setup/cloud/). Another way is to set up
MindsDB locally using
[Docker](/setup/self-hosted/docker/) or
[Python](/setup/self-hosted/pip/source/).


You will need to have MySQL installed locally to carry out the following tasks in your command line:

- Fire up the mysql server

 `mysql.server start`

- Login 

`mysql -u root -p`

- Create your database:

`CREATE DATABASE nlp_mindsdb;`

- Create a table:

```sql
CREATE TABLE tweets (
  id INTEGER,
  hate_speech INTEGER,
  offensive INTEGER,
  neither INTEGER,
  tweet VARCHAR(255),
  PRIMARY KEY (id)
);
```

---

Query OK, 0 rows affected (0.03 sec)

mysql> SHOW TABLES;
+-----------------------+
| Tables_in_nlp_mindsdb |
+-----------------------+
| tweets                |
+-----------------------+
1 row in set (0.00 sec)

---

- Next grant your user access to the new database table:

'GRANT ALL PRIVILEGES ON `nlp_mindsdb.tweets` TO user@localhost;'

***output should read:***
`Query OK, 0 rows affected (0.01 sec)`

---

## Understanding the Data

The Hugging Face [transformer model]() you will be using for this exercise was pre-trained on an extensive dataset, referenced on the accompanying [GitHub](). You do not need an additional datatset for this tutorial, but this next section will show you how to import data from a dataset into your newly created MySQL table:

- Load the data from your dataset into the `tweets` table:

```sql
mysql> LOAD DATA LOCAL INFILE '/Users/alissa/Downloads/tweets.csv' INTO TABLE tweets FIELDS TERMINATED BY `,`;
```

```
Query OK, 24784 rows affected, 17300 warnings (0.26 sec)
Records: 26952  Deleted: 0  Skipped: 2168  Warnings: 17300
```

---

- Go ahead and confirm your import:

`SELECT * FROM tweets LIMIT `0`

```sql
------------------------------------------------------------+
    -> | id | hate_speech | offensive | neither | tweet                                                                                                                                         |
    -> +----+-------------+-----------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------+
    -> |  0 |           0 |         0 |       3 | !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your hou |. &amp; as a man you should always take the trash out...
    '> |  1 |           0 |         3 |       0 | !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st plac                                                        |
    '> |  2 |           0 |         3 |       0 | !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she                     |confused as shit
    '> +----+-------------+-----------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------+
```
---

## Connecting To MySQL Datsource

- Now that your MySQL database and table are configured, use *ngrok* to expose your local MySQL server:

`ngrok tcp 3306` 

- Next, head to `https://cloud.mindsdb.com/editor`.

Using SQL's, `CREATE DATABASE` statement and the credentials supplied by `ngrok` output, securely connect to MySQL right inside the MindsDB Cloud Editor:

```sql
CREATE DATABASE twitter_data  --- display name for database.
WITH ENGINE = 'mysql',        --- name of the mindsdb handler
PARAMETERS = {
  "user": "root",             --- your mysql username
  "password": "MyN3wP4ssw0rd",    --- your mysql password  
   "host": "6.tcp.ngrok.io",    ---ngrok host credentials 
  "port": "10105",                  ---ngrok forwarded port
  "database": "nlp_mindsdb"          --- database name
};
```

You should receive the following output,
`Query Successfully Executed`

- Go ahead and confirm the new database includes the tweets table you built in your command line:

```sql
SELECT *
FROM twitter_data.tweets
LIMIT 10;
```

***your output will look like this, but with 10 rows***

| id  | hate_speech | offensive | neither | tweet |
| --- | ----------- | --------- | ------- | ----- |
| 0 | 0 | 0 | 3 | !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out... |
| 1 | 0 | 3 | 0 | !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!! |

---

## Creating a Predictor

Now that you're connected to MySQL, it's time to create your predictor model.

- First, navigate to the mindsdb database:

 `use mindsdb;`

Your output should read:
`Query successfully completed`

- Next, you definitely want to make sure your data is there. Go ahead and confirm:

- Now, it's time to create your nlp model!

```sql
CREATE MODEL mindsdb.hf_test
PREDICT PRED
USING
engine = 'huggingface',
task = 'text-classification',
model_name = "Hate-speech-CNERG/bert-base-uncased-hatexplain",
input_column = 'tweet',
labels = ['hate_speech', 'neither', 'offensive'];
```

| hf_test | huggingface | mindsdb | true | 1 | generating | [NULL] | PRED | up_to_date | 23.3.4.0 | [NULL] | [NULL] | {'target': 'PRED', 'using': {'task': 'text-classification', 'model_name': 'Hate-speech-CNERG/bert-base-uncased-hatexplain', 'input_column': 'tweet', 'labels': ['hate_speech', 'neither', 'offensive']}}  | [NULL] |


## Checking The Status of a Predictor

- Next up, check the status of your predictor:

```sql
SELECT *
FROM mindsdb.models 
WHERE name = 'hf_test';
```

| hf_test | huggingface | mindsdb | 1 | complete | [NULL] | PRED | up_to_date | 23.3.5.0 | [NULL] | [NULL] | {'target': 'PRED', 'using': {'task': 'text-classification', 'model_name': 'Hate-speech-CNERG/bert-base-uncased-hatexplain', 'input_column': 'tweet', 'labels': ['hate_speech', 'neither', 'offensive']}} | [NULL] | [NULL] | [NULL] | [NULL] | 2023-03-29 17:15:38.683663 |

---

`DESCRIBE PREDICTOR mindsdb.hf_test;`

```sql
{"input_column":"tweet","labels":["hate_speech","neither","offensive"],"labels_map":{"hate speech":"hate_speech","normal":"neither","offensive":"offensive"},"max_length":512,"model_name":"Hate-speech-CNERG/bert-base-uncased-hatexplain","target":"PRED","task":"text-classification","task_proper":"text-classification"}
```

## Training a Predictor

Now that your model is finished generating, you can go ahead and test it out! ***Note: In order to confirm your new model's efficiency, you will most likely use some language you don't like or agree with here. Just keep in mind, you can ultimately use this highly effective technology to do good! Do not follow the tutorial if you intent to use this malicously.***

Test Query Examples:

```sql
SELECT *
FROM mindsdb.hf_test
WHERE text = 'I like you. I love you.';
```

| PRED | PRED_explain | text |
| ---- | ------------ | ---- |
| neither | {"hate_speech":0.03551715984940529,"neither":0.7747423648834229,"offensive":0.18974047899246216} | I like you. I love you. |

---

```sql
SELECT *
FROM mindsdb.hf_test
WHERE text = 'I hate negroes'
```

| PRED | PRED_explain | text |
| ---- | ------------ | ---- |
| hate_speech | {"hate_speech":0.82469242811203,"neither":0.05819767713546753,"offensive":0.11710995435714722} | I hate negroes |

---

```sql
SELECT *
FROM mindsdb.hf_test
WHERE text = 'You are a dumb whore';
```

| PRED | PRED_explain | text |
| ---- | ------------ | ---- |
| offensive | {"hate_speech":0.06079000607132912,"neither":0.35908129811286926,"offensive":0.5801286697387695} | You are a dumb whore |

---

## Conclusion