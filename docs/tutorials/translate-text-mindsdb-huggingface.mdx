---
title: Multilingual Spam Data Translation with MindsDB and HuggingFace
sidebarTitle: Learn how to connect MindsDB to Hugging Face models for Multilingual Spam Data Text Translation
---

## Introduction

The internet has completely revolutionized the way we communicate. Social media, email and text message have become our primary forms of communication. While this brings a lot of benefits, it also leaves us vulnerable to malicious activities, specifically spam. Spam is defined by Merriam Webster's Dictionary as, "unsolicited usually commercial messages (such as emails, text messages, or Internet postings) sent to a large number of recipients or posted in a large number of places".

Receiving spam messages can cause a lot of concern for digital users. Luckily, advances in Natural Processing Language, or NLP, are being used to combat this 

In this tutorial, I'm going to show you how to use MindsDB and Hugging Face to identify spam in a multilingual dataset.

## Data Setup

We're going to use this [dataset](https://www.kaggle.com/datasets/rajnathpatel/multilingual-spam-data?resource=download) for this tutorial. Our **datasource** will be PostgreSQL.

Make sure you have a working [MindsDB Cloud Acccount](https://cloud.mindsdb.com/) or a local installation of MindsDB running so you can follow along with this tutorial. I'm going to be using Docker to run MindsDB locally. You can learn how to setup Docker for MindsDB using the following resources:

- **Video:** [Setting Up Docker for MindsDB](https://www.youtube.com/watch?v=dadY-cUpUm0&t=39s)
- **Docs:** [Setup for Docker](https://docs.mindsdb.com/setup/self-hosted/docker)

If you want to learn how to set up your account at MindsDB Cloud, follow
[this guide](/setup/cloud/). Another way is to set up
MindsDB locally using
[Docker](/setup/self-hosted/docker/) or
[Python](/setup/self-hosted/pip/source/).

## Connecting the Data

### Understanding the Data

The dataset we are working with contains **multilingual spam data** for English, Hindi, German, and French. It is primarily used to test the zero-shot transfer for text classification using pretrained language models. The original data was in English and was Machine Translated in Hindi, German and French. The dataset contains the multilingual text and corresponding labels:

- ham: non spam text
- spam: spam text

### Adding Data in MindsDB Cloud Editor

The instructions for importing data using MindsDB's Cloud Editor go as follows:

1. Visit [MindsDB Cloud Editor](https://cloud.mindsdb.com/)
2. Click 'Login' or 'Create Account' and authenticate
3. Once logged in, click **Add Data**
4. Select **"Files"**
5. Click **"Import File"**
6. Choose the file to import
7. Name your dataset accordingly (no special characters or cases in db name)
8. Use `SELECT` SQL command to confirm the data was uploaded successfully:

### Adding Data Locally

I'm working locally, so I'll start by heading over to [Kaggle](https://www.kaggle.com/) and downloading [this dataset](https://www.kaggle.com/datasets/rajnathpatel/multilingual-spam-data?resource=download). 

Now that I have my dataset, I'm going to add it to my PostgreSQL database:

1. Initiate the super user mode: `psql postgres`
2. Create a user and a database with the user as the owner:

**input:**
```sql
CREATE USER username123 WITH PASSWORD 'password123';
```
**output:**
`CREATE ROLE`

**input:**
```sql
CREATE DATABASE nlp_mindsdb WITH OWNER 'username123';
```
**output:** 
`CREATE DATABASE`

3. Next, let's type `\l` to list our PostgreSQL databases and ensure ours was created.

```sql
                               List of databases
Name     |      Owner      | Encoding | Collate | Ctype | Access privileges 
-------------+-----------------+----------+---------+-------+-------------------
 nlp_mindsdb | pg4e_4c0b06f09f | UTF8     | C       | C     | 
 postgres    | user            | UTF8     | C       | C     | 

(4 rows)
```

4. Quit the super user mode:
 `\q`

5. Access the database as a user:
`psql -U pg4e_4c0b06f09f nlp_mindsdb`

To use SQL for data manipulation, we have to load our data into the system. Let’s look at the CSV file first. 

**input:**
```sql
CREATE TABLE mindsdb_1
 (labels TEXT, text_message TEXT, text_hi TEXT,
  text_de TEXT, text_fr TEXT);
```

**output:**
`CREATE TABLE`

Great. Now we have our empty table in our database. Let's import our data:

**input:**
```sql
\copy mindsdb_1(labels, text, text_hi, text_de, text_fr)
FROM '/Users/alissa/Downloads/nlp_dataset.csv' WITH DELIMITER ',' CSV;
```

**output:**
`COPY 5573`

Let's check if our data loaded in properly:

**input:**
`SELECT COUNT(*) FROM mindsdb_1;`

**output:**
`11146`

Nice, we have 11146 rows/records in our new database and we are on our way! 

### Connecting MindsDB to PostgreSQL Database:

Now you know how to build a database with PostgreSQL in your command line. Awesome. Let's connect to it with MindsDB.

1. The first thing I'm going to do is navigate to `http://127.0.0.1:47334` and click "Add Data".

2. Next, I'm going to select my datasource, PostgreSQL.

3. Once you select the datasource, you will be prompted to enter your database credentials. 

4. Next, **Test Connection**:

![test](docs/tutorials/test_connect.png)

5. `SHOW DATABASES;`

![showdb](docs/tutorials/data_confirm.png)

6. Preview the dataset

**input:**
```sql
SELECT * FROM nlp_spam.mindsdb_1
LIMIT 3;`
```

**output:**
```
+------------+-------------+-----------------------------------------------------------------+--------------------------------+
| labels |             text           |      text_hi   |             text_de  |   text_fr                         |
+------------+--- ---------+-----------------------------------------------------------------+--------------------------------+
| ham    | 'Go until jurong, crazy..' | 'Dakag बिंदु तक.'  | 'Gehen bis jurong..'| 'Allez jusqu...'                  |
+------------+-------------+-----------------------------------------------------------------+--------------------------------+
| ham   | 'Ok lar... Joking wif u...' | `ओके लामर.... `   | `Ok... joking'   | `J'ai fait une blague sur le wif...`|
+------------+-------------+-----------------------------------------------------------------+--------------------------------+
| spam  | 'Free entry in 2 a wkly...' | 'Fktatatat मई...'| 'Freier Eintrit' | 'Entrée libre dans 2 a wkly comp...'|
+------------+-------------+-----------------------------------------------------------------+--------------------------------+
```

### Creating a Predictor models

Great job so far. We're about to start the most important part of this tutorial. Before we dig into the syntax, I want to go over a few things that I researched and thought out pretty thoroughly. The main goal of this tutorial is to demonstrate how we can use MindsDB and Hugging Face to perform multilingual spam data translations on our dataset.

The Hugging Face model transformer provided in the cooresponding GitHub issue results in the following output (upon being run many times and in many different ways):

**input:**
```sql
CREATE MODEL spam_nlp
PREDICT spam
USING
engine = 'huggingface',
task = 'text-classification',
model_name = 'bert-base-multilingual-cased',
input_column = 'text',
labels = ['spam', 'ham'];
```
**output:**
```
Not supported task for model: fill-mask.
Should be one of text-classification, zero-shot-classification, translation, summarization
```

After doing some research, it became apparent that the appropriate model for this task is the[roberta-base-finetuned-sms-spam-detection](https://huggingface.co/mariagrandury/roberta-base-finetuned-sms-spam-detection). This transformer model is a fine-tuned version of roberta-base on the sms_spam dataset.

```sql
CREATE MODEL spam_translation
PREDICT spam
USING
engine = 'huggingface',
task = 'text-classification',
model_name = 'mariagrandury/roberta-base-finetuned-sms-spam-detection',
input_column = 'text',
labels = ['spam', 'ham'];
```
After you create your model, your output should read `Query successfully completed`.
**Make sure you don't get an error message here. If you do, you may have to edit your code..**

### Checking the Status of a Predictor

Before we go any further, we can use the SELECT statement to check on the status of our predictor: 

```sql
SELECT *
FROM mindsdb.models
WHERE name = 'spam_translation';
```

Make sure this output to reads `complete` before moving forward.

### Training a Predictor

Now that we've created our predictor model, let's go ahead and test it out.
